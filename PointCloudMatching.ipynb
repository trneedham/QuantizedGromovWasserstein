{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Matching\n",
    "\n",
    "This notebook demonstrates the basic functionality of the quantized Gromov-Wasserstein (qGW) algorithm for matching low-dimensional point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import networkx as nx\n",
    "import ot\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from random import sample, uniform\n",
    "\n",
    "import pywavefront\n",
    "\n",
    "from quantizedGW import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Cloud Data\n",
    "\n",
    "We'll use point clouds from the [CAPOD database](https://sites.google.com/site/pgpapadakis/home/CAPOD). There are 15 classes of shapes and 12 samples per class. Loading requires `pywavefront`. We'll immediately compute the pairwise distance matrix for the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_class = 8\n",
    "shape_sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./data/CAPOD/class'+str(shape_class)+'/m'+str((shape_class-1)*12+shape_sample)+'.obj'\n",
    "scene = pywavefront.Wavefront(path)\n",
    "\n",
    "X1 = np.array(scene.vertices)\n",
    "Dist1 = euclidean_distances(X1)\n",
    "\n",
    "print('Number of points:', len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X1[:,0],-X1[:,1],X1[:,2], marker='o', s=20, c='goldenrod', alpha=0.2)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "# ax.set_axis_off()\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we pick another shape and compute its distance matrix. We also create probability vectors for each shape (we'll use uniform measure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_class = 8\n",
    "shape_sample = 1\n",
    "\n",
    "path='./data/CAPOD/class'+str(shape_class)+'/m'+str((shape_class-1)*12+shape_sample)+'.obj'\n",
    "scene = pywavefront.Wavefront(path)\n",
    "\n",
    "X2 = np.array(scene.vertices)\n",
    "Dist2 = euclidean_distances(X2)\n",
    "\n",
    "print('Number of points:', len(X2))\n",
    "\n",
    "p1 = ot.unif(len(X1))\n",
    "p2 = ot.unif(len(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X2[:,0],-X2[:,1],X2[:,2], marker='o', s=20, c='goldenrod', alpha=0.2)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "# ax.set_axis_off()\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Datasets\n",
    "\n",
    "We now compute probabilistic matchings between the datasets. First, this is done with the standard Gromov-Wasserstein algorithm. We are using the function from the Python Optimal Transport `pot` package.\n",
    "\n",
    "**Warning:** The computation becomes quite long if the shapes you are matching are larger than ~2k points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "coup, log = ot.gromov.gromov_wasserstein(Dist1, Dist2, p1, p2, \n",
    "                                        'square_loss', verbose=False, log=True)\n",
    "time_gw = time.time() - start\n",
    "print('GW Compute Time:',time_gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize a matching via *color transfer*: we color the source point cloud (by, say, distance to a fixed point), then transfer this coloring to the target point cloud. The color of a point in the target point cloud is the weighted average of the colors of the points which match to it under the matching, with weights coming from the coupling.\n",
    "\n",
    "The figure below shows that GW did a good job of matching points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 1000\n",
    "c1 = Dist1[point,:]\n",
    "c2 = [np.dot(coup[:,j],c1)/np.sum(coup[:,j]) for j in range(Dist2.shape[0])]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X1[:,0],-X1[:,1],X1[:,2], marker='o', s=20, c=c1, alpha=0.15)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Source Point Cloud')\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.scatter(X2[:,0],-X2[:,1],X2[:,2], marker='o', s=20, c=c2, alpha=0.2)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Targe Point Cloud with Color Transferred by GW \\n Compute Time: {}s'.format(np.round(time_gw,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute a matching using the qGW algorithm. The function takes subsets of the source and target point clouds as input. We sample randomly at a user-defined rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = .1\n",
    "\n",
    "samples = int(sample_size*len(X1))\n",
    "\n",
    "node_subset1 = list(set(sample(list(range(X1.shape[0])),samples)))\n",
    "node_subset2 = list(set(sample(list(range(X2.shape[0])),samples)))\n",
    "\n",
    "start = time.time()\n",
    "coup_qgw = compressed_gw_point_cloud(Dist1,Dist2,p1,p2,\n",
    "                                      node_subset1,node_subset2,\n",
    "                                      verbose = True,return_dense = True)\n",
    "time_qgw = time.time()-start\n",
    "\n",
    "print('qGW Compute Time:',time_qgw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the color transfer for `qGW` shows that the matching also picks up the structure of the point cloud, with a much faster compute time. The improvement in computation speed increases with the size of the point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 1000\n",
    "c1 = Dist1[point,:]\n",
    "c2 = [np.dot(coup_qgw[:,j],c1)/np.sum(coup_qgw[:,j]) for j in range(Dist2.shape[0])]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X1[:,0],-X1[:,1],X1[:,2], marker='o', s=20, c=c1, alpha=0.15)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Source Point Cloud')\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.scatter(X2[:,0],-X2[:,1],X2[:,2], marker='o', s=20, c=c2, alpha=0.2)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Targe Point Cloud with Color Transferred by qGW \\n Compute Time: {}s'.format(np.round(time_qgw,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, entropy regularized GW (erGW) with a large regularization coefficient can handle larger datasets than GW with faster compute time, but the color transfer quality is diminished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 100\n",
    "\n",
    "start = time.time()\n",
    "coup_er, log = ot.gromov.entropic_gromov_wasserstein(Dist1, Dist2, p1, p2,\n",
    "                                                  'square_loss', epsilon=epsilon, \n",
    "                                                   log=True, verbose=False)\n",
    "time_er = time.time() - start\n",
    "print('erGW Compute Time:',time_er)\n",
    "\n",
    "point = 1000\n",
    "c1 = Dist1[point,:]\n",
    "c2 = [np.dot(coup_er[:,j],c1)/np.sum(coup_er[:,j]) for j in range(Dist2.shape[0])]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X1[:,0],-X1[:,1],X1[:,2], marker='o', s=20, c=c1, alpha=0.15)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Source Point Cloud')\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.scatter(X2[:,0],-X2[:,1],X2[:,2], marker='o', s=20, c=c2, alpha=0.2)\n",
    "ax.view_init(elev=10., azim=10)\n",
    "ax.grid(True)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "plt.title('Targe Point Cloud with Color Transferred by erGW \\n Compute Time: {}s'.format(np.round(time_er,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying Matching Quality\n",
    "\n",
    "We can quantify the ability of qGW to find good matchings as follows. Give a point cloud $X$, we permute the order of its points and perturb the points with noise to get a new point cloud $\\widetilde{X}$. There is a ground truth optimal matching of $X$ and $\\widetilde{X}$. Let $\\mu$ be a coupling of $X$ and $\\widetilde{X}$. Given $x \\in X$, there is a ground truth match $\\widetilde{x} \\in \\widetilde{X}$ and a matched point returned from $\\mu$ as \n",
    "$$\n",
    "\\widetilde{y} : = \\mathrm{argmax} \\mu(x,\\cdot).\n",
    "$$\n",
    "We compute the distortion score of $\\mu$ as\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\|\\widetilde{x} - x\\|^2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbPointCloud(X,noise = 0.1):\n",
    "    \n",
    "    perm = np.random.permutation(np.eye(len(X)))\n",
    "    X_pert = np.matmul(perm,X) + noise*(np.random.rand(X.shape[0],X.shape[1]) - np.random.rand(X.shape[0],X.shape[1]))\n",
    "    \n",
    "    return X_pert, perm\n",
    "\n",
    "def matching_distortion(X1,X2,matching,perm):\n",
    "    \n",
    "    dis = 0\n",
    "    \n",
    "    for j in range(len(X1)):\n",
    "        dis += np.linalg.norm(X2[matching[j],:] - X2[np.argmax(perm[:,j]),:])**2\n",
    "        \n",
    "    return dis/X1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `X1` above, let's perturb it and compute the distortion scores of GW, qGW and erGW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_pert, perm = perturbPointCloud(X1,noise = .01*np.max(Dist1))\n",
    "Dist1_pert = euclidean_distances(X1_pert,X1_pert)\n",
    "\n",
    "start = time.time()\n",
    "coup, log = ot.gromov.gromov_wasserstein(Dist1, Dist1_pert, p1, p1, \n",
    "                                        'square_loss', verbose=False, log=True)\n",
    "matching_gw = [np.argmax(coup[j,:]) for j in range(len(X1))]\n",
    "\n",
    "print('GW Done in {} seconds'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "sample_size = .1 # Increase to increase quality and compute time\n",
    "samples = int(sample_size*len(X1))\n",
    "node_subset1 = list(set(sample(list(range(X1.shape[0])),samples)))\n",
    "node_subset2 = list(set(sample(list(range(X2.shape[0])),samples)))\n",
    "\n",
    "coup_qgw = compressed_gw_point_cloud(Dist1,Dist1_pert,p1,p1,\n",
    "                                      node_subset1,node_subset2,\n",
    "                                      verbose = False,return_dense = True)\n",
    "matching_qgw = [np.argmax(coup_qgw[j,:]) for j in range(len(X1))]\n",
    "\n",
    "print('qGW Done in {} seconds'.format(time.time()-start))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "epsilon = 100 # Decrease to increase quality, but increase compute time\n",
    "coup_er, log = ot.gromov.entropic_gromov_wasserstein(Dist1, Dist1_pert, p1, p1,\n",
    "                                                  'square_loss', epsilon=epsilon, \n",
    "                                                   log=True, verbose=False)\n",
    "matching_er = [np.argmax(coup_er[j,:]) for j in range(len(X1))]\n",
    "\n",
    "print('erGW Done in {} seconds'.format(time.time()-start))\n",
    "\n",
    "\n",
    "print('Distortion Scores:')\n",
    "print('GW:{}'.format(matching_distortion(X1,X1_pert,matching_gw,perm)))\n",
    "print('qGW:{}'.format(matching_distortion(X1,X1_pert,matching_qgw,perm)))\n",
    "print('erGW:{}'.format(matching_distortion(X1,X1_pert,matching_er,perm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that qGW is generally close to GW and is sometimes better than GW (for larger datasets)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
